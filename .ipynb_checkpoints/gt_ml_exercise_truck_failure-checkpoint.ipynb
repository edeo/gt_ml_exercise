{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the workshop for this week, you are to select a data set from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the website, a description of the data set.\n",
    "\n",
    "\"The dataset consists of data collected from heavy Scania \n",
    "trucks in everyday usage. The system in focus is the \n",
    "Air Pressure system (APS) which generates pressurised \n",
    "air that are utilized in various functions in a truck, \n",
    "such as braking and gear changes. The datasets' \n",
    "positive class consists of component failures \n",
    "for a specific component of the APS system. \n",
    "The negative class consists of trucks with failures \n",
    "for components not related to the APS. The data consists \n",
    "of a subset of all available data, selected by experts. \"\n",
    "\n",
    "\n",
    "\"ttribute Information:\n",
    "\n",
    "Attribute Information: \n",
    "The attribute names of the data have been anonymized for \n",
    "proprietary reasons.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('aps_failure_training_set.csv',skiprows=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, I am wrangling the data, converting the target column into a 0 and a 1, 0 when the target class is negative and 1 when the target class is positive. \n",
    "\n",
    "I then remove the class column, and then make sure all of the columns are numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "df['target'] = np.where(df['class']=='neg', 0, 1)\n",
    "df = df.loc[:, df.columns != 'class']\n",
    "\n",
    "\n",
    "for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataset\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am splitting the attribute columns from the target column.\n",
    "\n",
    "Then, if there are any missing values, I using the mean of that column to fill the values.\n",
    "\n",
    "Then, I am scaling the columns, so that columns with larger numbers don't impact the model columns with lower numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below, I am creating the Kfold indexes to do the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv = KFold(n_splits=10,random_state=42,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is read to fit a model. I create a dictionary to hold the scores for evaluating the models. \n",
    "\n",
    "Then I create an instance of the model.\n",
    "\n",
    "Then I use the cross validation I created above to create a test and train split to build the model. The modelis then fit, and then used to predict the the target on the test set. The expected target value is then used for the the evaluation. \n",
    "\n",
    "I do this for a random forest model first, and the for a Support Vector Classification model. \n",
    "\n",
    "I have written out the code for a K nearest neighbors model, however it took too long to run on my machine. If I had more time or more computing power, I would run this code to try and see if it performed any better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "\n",
    "best_random = RandomForestClassifier()\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "  print(\"Train Index:\",train_index,\"\\n\")\n",
    "  print(\"Test Index:\",test_index)\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "  best_random.fit(X_train, y_train)\n",
    "  predicted = best_random.predict(X_test)\n",
    "  expected  = y_test\n",
    "  random_forest_scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "  random_forest_scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "  random_forest_scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "  random_forest_scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation scores  for the random forrest model are as follows:\\n\")\n",
    "\n",
    "print(pd.DataFrame(random_forest_scores).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "\n",
    "best_svc = SVC()\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "  print(\"Train Index:\",train_index,\"\\n\")\n",
    "  print(\"Test Index:\",test_index)\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "  best_svc.fit(X_train, y_train)\n",
    "  predicted = best_svc.predict(X_test)\n",
    "  expected  = y_test\n",
    "  svc_scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "  svc_scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "  svc_scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "  svc_scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Validation scores for the svc model are as follows:\\n\")\n",
    "\n",
    "print(pd.DataFrame(svc_scores).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn_scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "\n",
    "best_knn = KNeighborsClassifier(n_neighbors=12)\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "  print(\"Train Index:\",train_index,\"\\n\")\n",
    "  print(\"Test Index:\",test_index)\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "  best_knn.fit(X_train, y_train)\n",
    "  predicted = best_knn.predict(X_test)\n",
    "  expected  = y_test\n",
    "  knn_scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "  knn_scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "  knn_scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "  knn_scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "print(\"Validation scores for the knn are as follows:\\n\")\n",
    "\n",
    "print(pd.DataFrame(knn_scores).mean())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
